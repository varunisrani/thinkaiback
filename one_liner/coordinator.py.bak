from typing import Dict, Any, List, Optional
import json
import os
from datetime import datetime
from .agents.semantic_distiller_agent import SemanticDistillerAgent
from .agents.tag_injector_agent import TagInjectorAgent
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OneLinerCoordinator:
    def __init__(self):
        self.semantic_distiller = SemanticDistillerAgent()
        self.tag_injector = TagInjectorAgent()
        
        # Create data directory if it doesn't exist
        os.makedirs("data/summaries", exist_ok=True)
        logger.info("Initialized OneLinerCoordinator")
    
    async def generate_one_liner(self, script_data: Dict[str, Any]) -> Dict[str, Any]:
        """Generate one-liner summaries for the script.
        This is the main entry point called by the UI."""
        try:
            # Extract the parsed data from the script ingestion results
            scene_data = script_data.get("parsed_data", {})
            if not scene_data:
                logger.error("No parsed script data found in input")
                raise ValueError("No parsed script data found")
                
            logger.info(f"Processing script with {len(scene_data)} scenes")
            
            # Process the script through the one-liner pipeline
            result = await self.process_script(scene_data)
            
            # Add formatted text representation
            result["formatted_text"] = self._format_summaries(result)
            
            return result
            
        except Exception as e:
            logger.error(f"Failed to generate one-liner: {str(e)}", exc_info=True)
            return {
                "error": str(e),
                "status": "failed",
                "formatted_text": f"Error: Failed to generate one-liner - {str(e)}"
            }
    
    def _format_summaries(self, result: Dict[str, Any]) -> str:
        """Format the summaries into readable text."""
        output = []
        
        # Add timestamp
        output.append(f"Generated on: {result.get('timestamp', 'Not specified')}\n")
        
        # Format summaries
        summaries = result.get("summaries", {}).get("summaries", [])
        if summaries:
            output.append("SCENE SUMMARIES")
            output.append("=" * 80 + "\n")
            
            for scene in summaries:
                scene_num = scene.get("scene_number", "Unknown")
                summary = scene.get("summary", "No summary available")
                output.extend([
                    f"Scene {scene_num}:",
                    f"{summary}\n"
                ])
        
        # Format story threads
        threads = result.get("summaries", {}).get("story_threads", {})
        if threads:
            output.extend([
                "\nSTORY THREADS",
                "=" * 80 + "\n"
            ])
            
            for thread, scenes in threads.items():
                output.append(f"{thread}:")
                output.append(f"  Appears in scenes: {', '.join(str(s) for s in scenes)}\n")
        
        # Format character arcs
        arcs = result.get("summaries", {}).get("character_arcs", {})
        if arcs:
            output.extend([
                "\nCHARACTER ARCS",
                "=" * 80 + "\n"
            ])
            
            for char, appearances in arcs.items():
                output.append(f"{char}:")
                for app in appearances:
                    scene = app.get("scene", "Unknown")
                    arc = app.get("arc_point", "No arc point")
                    emotion = app.get("emotional_state", "No emotional state")
                    output.append(f"  Scene {scene}: {arc} - {emotion}")
                output.append("")
        
        # Format tags
        tags = result.get("tags", {}).get("scene_tags", {})
        if tags:
            output.extend([
                "\nSCENE TAGS",
                "=" * 80 + "\n"
            ])
            
            for scene, scene_tags in tags.items():
                output.append(f"Scene {scene}:")
                output.append(f"  {', '.join(scene_tags)}\n")
        
        return "\n".join(output)
    
    async def process_script(
        self,
        script_text: str,
        department_focus: Optional[List[str]] = None,
        workflow_config: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Process a script through the enhanced workflow pipeline.
        
        Args:
            script_text: The input script text
            department_focus: List of departments to focus analysis on
            workflow_config: Configuration for approval workflow
            
        Returns:
            Dict containing processed results including summaries, tags, and workflow data
        """
        try:
            logger.info("Starting script processing workflow")
            
            # Initialize workflow tracking
            workflow_status = {
                "started_at": datetime.now().isoformat(),
                "current_stage": "analysis",
                "completed_stages": [],
                "errors": [],
                "warnings": []
            }
            
            # Generate initial summaries with emotional analysis
            try:
                summaries = await self.semantic_distiller.generate_summaries(
                    script_text,
                    department_focus=department_focus
                )
                workflow_status["completed_stages"].append({
                    "stage": "summary_generation",
                    "completed_at": datetime.now().isoformat(),
                    "success": True
                })
            except Exception as e:
                logger.error(f"Error generating summaries: {str(e)}")
                workflow_status["errors"].append({
                    "stage": "summary_generation",
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                })
                raise
            
            # Process tags and generate metadata
            try:
                workflow_status["current_stage"] = "tag_processing"
                tag_data = await self.tag_injector.inject_tags(summaries)
                workflow_status["completed_stages"].append({
                    "stage": "tag_processing",
                    "completed_at": datetime.now().isoformat(),
                    "success": True
                })
            except Exception as e:
                logger.error(f"Error processing tags: {str(e)}")
                workflow_status["errors"].append({
                    "stage": "tag_processing",
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                })
                raise
            
            # Initialize approval workflow if config provided
            if workflow_config:
                try:
                    workflow_status["current_stage"] = "workflow_setup"
                    approval_workflow = self._setup_approval_workflow(
                        summaries,
                        tag_data,
                        workflow_config
                    )
                    workflow_status["completed_stages"].append({
                        "stage": "workflow_setup",
                        "completed_at": datetime.now().isoformat(),
                        "success": True
                    })
                except Exception as e:
                    logger.error(f"Error setting up workflow: {str(e)}")
                    workflow_status["errors"].append({
                        "stage": "workflow_setup",
                        "error": str(e),
                        "timestamp": datetime.now().isoformat()
                    })
                    raise
            
            # Prepare final result structure
            result = {
                "summaries": summaries,
                "metadata": {
                    "tags": tag_data["scene_tags"],
                    "cross_references": tag_data["cross_references"],
                    "story_elements": tag_data["story_elements"],
                    "department_insights": tag_data.get("department_insights", {}),
                    "emotional_progression": tag_data.get("emotional_progression", {})
                },
                "workflow": {
                    "status": workflow_status,
                    "approval_data": approval_workflow if workflow_config else None
                },
                "ui_metadata": {
                    "quick_references": self._generate_quick_references(summaries, tag_data),
                    "emotional_journey": self._extract_emotional_journey(tag_data),
                    "department_views": self._organize_department_views(
                        summaries,
                        tag_data,
                        department_focus
                    )
                }
            }
            
            workflow_status["current_stage"] = "completed"
            workflow_status["completed_at"] = datetime.now().isoformat()
            
            logger.info("Successfully completed script processing workflow")
            return result
            
        except Exception as e:
            logger.error(f"Error in script processing workflow: {str(e)}")
            if workflow_status:
                workflow_status["current_stage"] = "failed"
                workflow_status["failed_at"] = datetime.now().isoformat()
                workflow_status["final_error"] = str(e)
            raise ValueError(f"Script processing failed: {str(e)}")
    
    def _setup_approval_workflow(
        self,
        summaries: Dict[str, Any],
        tag_data: Dict[str, Any],
        workflow_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Setup approval workflow tracking for scenes."""
        approval_workflow = {}
        
        for scene_id in summaries.keys():
            approval_workflow[scene_id] = {
                "status": "pending",
                "approvers": workflow_config.get("approvers", []),
                "approvals": [],
                "notes": [],
                "last_modified": datetime.now().isoformat(),
                "department_status": {
                    dept: "pending" for dept in workflow_config.get("departments", [])
                }
            }
        
        return approval_workflow
    
    def _generate_quick_references(
        self,
        summaries: Dict[str, Any],
        tag_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate quick reference data for UI."""
        return {
            "key_scenes": self._identify_key_scenes(summaries, tag_data),
            "character_arcs": self._extract_character_arcs(summaries),
            "technical_requirements": self._compile_technical_requirements(tag_data),
            "story_threads": tag_data.get("story_elements", {}).get("themes", [])
        }
    
    def _extract_emotional_journey(
        self,
        tag_data: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Extract emotional progression data for visualization."""
        emotional_journey = []
        
        for scene_id, tags in tag_data.get("scene_tags", {}).items():
            if "emotional" in tags:
                emotional_journey.append({
                    "scene_id": scene_id,
                    "emotions": tags["emotional"],
                    "intensity": self._calculate_emotional_intensity(tags["emotional"])
                })
        
        return sorted(emotional_journey, key=lambda x: int(x["scene_id"]))
    
    def _organize_department_views(
        self,
        summaries: Dict[str, Any],
        tag_data: Dict[str, Any],
        department_focus: Optional[List[str]]
    ) -> Dict[str, Any]:
        """Organize data by department for focused views."""
        department_views = {}
        
        departments = department_focus if department_focus else [
            "camera", "lighting", "sound", "art", "wardrobe", "makeup"
        ]
        
        for dept in departments:
            relevant_scenes = []
            for scene_id, tags in tag_data.get("scene_tags", {}).items():
                if dept in " ".join(tags.get("department", [])):
                    relevant_scenes.append({
                        "scene_id": scene_id,
                        "summary": summaries[scene_id],
                        "technical_notes": [
                            tag for tag in tags.get("technical", [])
                            if tag.startswith(f"{dept}_")
                        ],
                        "approval_status": tag_data.get("approval_workflow", {})
                            .get(scene_id, {}).get("department_status", {}).get(dept)
                    })
            
            department_views[dept] = {
                "scenes": relevant_scenes,
                "requirements": self._compile_department_requirements(dept, tag_data),
                "notes": tag_data.get("department_insights", {}).get(dept, [])
            }
        
        return department_views
    
    def _identify_key_scenes(
        self,
        summaries: Dict[str, Any],
        tag_data: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Identify and categorize key scenes."""
        key_scenes = []
        
        for scene_id, tags in tag_data.get("scene_tags", {}).items():
            if any(tag.startswith("key_") for tag in tags.get("story", [])):
                key_scenes.append({
                    "scene_id": scene_id,
                    "summary": summaries[scene_id],
                    "importance": self._calculate_scene_importance(tags),
                    "type": next(
                        (tag.replace("key_", "") for tag in tags.get("story", [])
                        if tag.startswith("key_")),
                        "general"
                    )
                })
        
        return sorted(key_scenes, key=lambda x: x["importance"], reverse=True)
    
    def _extract_character_arcs(
        self,
        summaries: Dict[str, Any]
    ) -> Dict[str, List[Dict[str, Any]]]:
        """Extract character arc information from summaries."""
        character_arcs = {}
        
        for scene_id, summary in summaries.items():
            for character in summary.get("characters", []):
                if character not in character_arcs:
                    character_arcs[character] = []
                
                character_arcs[character].append({
                    "scene_id": scene_id,
                    "action": summary.get("character_actions", {}).get(character),
                    "emotional_state": summary.get("character_emotions", {}).get(character)
                })
        
        return character_arcs
    
    def _compile_technical_requirements(
        self,
        tag_data: Dict[str, Any]
    ) -> Dict[str, List[str]]:
        """Compile technical requirements by department."""
        requirements = {}
        
        for scene_tags in tag_data.get("scene_tags", {}).values():
            for tech_tag in scene_tags.get("technical", []):
                dept = tech_tag.split("_")[0]
                if dept not in requirements:
                    requirements[dept] = []
                if tech_tag not in requirements[dept]:
                    requirements[dept].append(tech_tag)
        
        return requirements
    
    def _compile_department_requirements(
        self,
        department: str,
        tag_data: Dict[str, Any]
    ) -> List[str]:
        """Compile specific requirements for a department."""
        requirements = []
        
        for scene_tags in tag_data.get("scene_tags", {}).values():
            dept_reqs = [
                tag for tag in scene_tags.get("technical", [])
                if tag.startswith(f"{department}_")
            ]
            requirements.extend(dept_reqs)
        
        return list(set(requirements))
    
    def _calculate_emotional_intensity(
        self,
        emotion_tags: List[str]
    ) -> float:
        """Calculate emotional intensity score from tags."""
        intensity_map = {
            "high": 1.0,
            "medium": 0.6,
            "low": 0.3
        }
        
        intensities = [
            intensity_map[tag.split("_")[-1]]
            for tag in emotion_tags
            if tag.split("_")[-1] in intensity_map
        ]
        
        return sum(intensities) / len(intensities) if intensities else 0.5
    
    def _calculate_scene_importance(
        self,
        tags: Dict[str, List[str]]
    ) -> float:
        """Calculate scene importance score from tags."""
        importance_score = 0.0
        
        # Story elements contribute to importance
        importance_score += len(tags.get("story", [])) * 0.3
        
        # Technical complexity adds weight
        importance_score += len(tags.get("technical", [])) * 0.2
        
        # Emotional intensity factors in
        importance_score += len(tags.get("emotional", [])) * 0.25
        
        # Department involvement increases importance
        importance_score += len(tags.get("department", [])) * 0.25
        
        return min(importance_score, 1.0)  # Normalize to 0-1 range
    
    def _save_to_disk(self, data: Dict[str, Any]) -> str:
        """Save summary data to disk.
        
        Args:
            data: Dictionary containing summary data to save
            
        Returns:
            str: Path to the saved file
            
        Raises:
            IOError: If file cannot be written
            TypeError: If data is not JSON serializable
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"data/summaries/summary_{timestamp}.json"
            
            logger.info(f"Saving summary data to {filename}")
            
            # Validate data is JSON serializable
            try:
                json.dumps(data)
            except TypeError as e:
                logger.error(f"Data is not JSON serializable: {str(e)}")
                raise TypeError(f"Data is not JSON serializable: {str(e)}")
            
            # Create directory if it doesn't exist
            os.makedirs(os.path.dirname(filename), exist_ok=True)
        
            with open(filename, "w") as f:
                json.dump(data, f, indent=2)
            
            logger.info(f"Successfully saved {os.path.getsize(filename)} bytes to {filename}")
            return filename 
            
        except IOError as e:
            logger.error(f"Failed to write file {filename}: {str(e)}", exc_info=True)
            raise IOError(f"Failed to write summary file: {str(e)}")
        except Exception as e:
            logger.error(f"Unexpected error saving summary data: {str(e)}", exc_info=True)
            raise 